{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from lib.test import *\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=21, padding=10)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=15, padding=7)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=11, padding=5)\n",
    "        \n",
    "        self.batchnorm32 = nn.BatchNorm1d(num_features=32)\n",
    "        self.batchnorm64 = nn.BatchNorm1d(num_features=64)\n",
    "        self.batchnorm128 = nn.BatchNorm1d(num_features=128)\n",
    "        self.batchnorm512 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4736, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)     \n",
    "        \n",
    "        self.dropout2d = nn.Dropout2d(p=0.5)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x.unsqueeze(1))\n",
    "        x = F.relu(self.batchnorm32(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm64(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.batchnorm128(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Flatten input for fully connected layers\n",
    "        x = x.view(x.shape[0], -1) \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.batchnorm512(x))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.batchnorm512(x))\n",
    "        \n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "mixdata = h5py.File(\"../train/scsn_p_2000_2017_6sec_0.5r_pick_train_mix.hdf5\", \"r\")\n",
    "testdata = h5py.File(\"../test/scsn_p_2000_2017_6sec_0.5r_pick_test_mix.hdf5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 160 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from lib.utils import split_trainset\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "train_size = 1 * 10 ** 5\n",
    "train_ratio = 0.7\n",
    "test_size = 1 * 10 ** 4\n",
    "\n",
    "# Load test data\n",
    "train_val_data = mixdata[\"X\"][:train_size]\n",
    "train_val_labels = mixdata[\"pwave\"][:train_size]\n",
    "\n",
    "trainset, valset = split_trainset(train_val_data, train_val_labels, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Add Multi-GPU Support to Model \n",
    "In order to run the model on multiple GPU's, we can use the nn.DataParallel layer. This layer requires that we move all tensors to the cuda:0 (the default gpu) before we can pass them through the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize(model):\n",
    "    device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "    model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "  (conv3): Conv1d(64, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "  (batchnorm32): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm64): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm128): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm512): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=4736, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2d): Dropout2d(p=0.5)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (device == \"cuda\"):\n",
    "    model = parallelize(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define Loss Function and Optimizer\n",
    "Here we define the loss function and optimizer. For the loss function (criterion), we use the binary cross entropy with logits loss (BCEWithLogitsLoss). This function applies a sigmoid as well as calculates the cross entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Validation\n",
    "\n",
    "## TODO -- Save model on validation improvement. Then load model when testing and evaluating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: info=<RunInfo: run_uuid='70d056a5daa04a30b73051b16c4ae9f1', experiment_id=0, name='', source_type=4, source_name=('C:\\\\Users\\\\Patrick '\n",
       " 'Garcia\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\EEW\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), entry_point_name=None, user_id='unknown', status=1, start_time=1552025635486, end_time=None, source_version=None, lifecycle_stage='active', artifact_uri='.\\\\mlruns\\\\0\\\\70d056a5daa04a30b73051b16c4ae9f1\\\\artifacts'>, data=None>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:.\\mlruns\")\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/   10] | train loss: 0.0635 | validation loss: 3.0608\n",
      "Epoch [    2/   10] | train loss: 0.0417 | validation loss: 3.1152\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\EEW\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\EEW\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, labels in trainloader:\n",
    "        # ============================================\n",
    "        #            TRAINING\n",
    "        # ============================================\n",
    "        if (device == \"cuda\"):\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "        # Clear gradients in optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model.forward(batch)\n",
    "        # Calculate loss\n",
    "        if (device == \"cuda\"):\n",
    "            loss = criterion(output, labels.type(torch.cuda.LongTensor).view(labels.shape, 1))\n",
    "        else:\n",
    "            loss = criterion(output, labels.type(torch.LongTensor).view(labels.shape, 1))\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "\n",
    "            for batch, labels in val_loader:\n",
    "                # ============================================\n",
    "                #            VALIDATION\n",
    "                # ============================================\n",
    "                if (device == \"cuda\"):\n",
    "                    batch, labels = batch.to(device), labels.to(device)\n",
    "                # Forward pass\n",
    "                ouput = model.forward(batch)\n",
    "                # Calculate loss\n",
    "                if (device == \"cuda\"):\n",
    "                    loss = criterion(output, labels.type(torch.cuda.LongTensor).view(labels.shape, 1))\n",
    "                else:\n",
    "                    loss = criterion(output, labels.type(torch.LongTensor).view(labels.shape, 1))\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "    # Print epoch summary\n",
    "    t_loss_avg = train_loss / len(trainloader)\n",
    "    v_loss_avg = val_loss / len(val_loader)\n",
    "    \n",
    "    mlflow.log_metric(\"train_loss\", t_loss_avg)\n",
    "    mlflow.log_metric(\"val_loss\", v_loss_avg)\n",
    "    \n",
    "    train_losses.append(t_loss_avg)\n",
    "    val_losses.append(v_loss_avg)\n",
    "    \n",
    "    print('Epoch [{:5d}/{:5d}] | train loss: {:6.4f} | validation loss: {:6.4f}'.format(\n",
    "            epoch+1, epochs, t_loss_avg, v_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b99e50cf98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add learning curve plot\n",
    "train_loss = np.array(train_loss)\n",
    "\n",
    "plt.plot(train_losses, label=\"Training\")\n",
    "plt.plot(val_losses, label=\"Validation\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing Model Performance\n",
    "\n",
    "For testing model performance, we'll be using scikit learn's metrics library. Scikit learn provides a handful of builtin classfication metrics which we can take advantage of. In order to use them with pytorch, we'll have to move the tensors from GPU to CPU and convert them to numpy arrays. \n",
    "\n",
    "1. Classification Report  \n",
    "    a. Precision  \n",
    "    b. Recall  \n",
    "    c. F1 Score\n",
    "2. Accuracy\n",
    "3. AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Projects\\cloud\\P-Wave-CNN\\notebooks\\lib\\test.py\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(model, data_path, test_size, device)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\EEW\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m         raise RuntimeError(\n\u001b[0;32m    160\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\EEW\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "test_path = \"../test/scsn_p_2000_2017_6sec_0.5r_pick_test_mix.hdf5\"\n",
    "\n",
    "y_true, y_pred, y_probs = test_model(model, test_path, test_size, device=\"cuda\")\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=[\"pwave\", \"noise\"])\n",
    "report_dict = classification_report(y_true, y_pred, target_names=[\"pwave\", \"noise\"], output_dict=True)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "roc_auc_score = roc_auc_score(y_true, y_probs)\n",
    "\n",
    "print(report)\n",
    "print(\"Accuracy: {:.4}%\".format(accuracy * 100))\n",
    "print(\"ROC Score: \", roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c56c07deb2a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"device\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"auc_roc_score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.log_param(\"epochs\", epochs)\n",
    "mlflow.log_param(\"learning_rate\", lr)\n",
    "mlflow.log_param(\"device\", device)\n",
    "\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_metric(\"auc_roc_score\", roc_auc_score)\n",
    "\n",
    "for category in report_dict:\n",
    "    for metric, value in report_dict[category].items():\n",
    "        metric_name = category + \"_\" + metric\n",
    "        mlflow.log_metric(metric_name, value)\n",
    "        \n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2017JB015251\n",
    "2. http://scedc.caltech.edu/research-tools/deeplearning.html#picking_polarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
