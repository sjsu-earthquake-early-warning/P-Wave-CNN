{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from lib.test import *\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=21, padding=10)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=15, padding=7)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=11, padding=5)\n",
    "        \n",
    "        self.batchnorm32 = nn.BatchNorm1d(num_features=32)\n",
    "        self.batchnorm64 = nn.BatchNorm1d(num_features=64)\n",
    "        self.batchnorm128 = nn.BatchNorm1d(num_features=128)\n",
    "        self.batchnorm512 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4736, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)     \n",
    "        \n",
    "        self.dropout2d = nn.Dropout2d(p=0.5)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x.unsqueeze(1))\n",
    "        x = F.relu(self.batchnorm32(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm64(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.batchnorm128(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Flatten input for fully connected layers\n",
    "        x = x.view(x.shape[0], -1) \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.batchnorm512(x))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(self.batchnorm512(x))\n",
    "        \n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "mixdata = h5py.File(\"../train/scsn_p_2000_2017_6sec_0.5r_pick_train_mix.hdf5\", \"r\")\n",
    "testdata = h5py.File(\"../test/scsn_p_2000_2017_6sec_0.5r_pick_test_mix.hdf5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trainset(train_val_data, train_val_labels, ratio):\n",
    "    train_ratio = ratio\n",
    "    \n",
    "    trainsize = int(len(train_val_data) * train_ratio)\n",
    "    \n",
    "    trainset = train_val_data[:trainsize]\n",
    "    trainlabels = train_val_labels[:trainsize]\n",
    "    \n",
    "    valset = train_val_data[trainsize:]\n",
    "    valabels = train_val_labels[trainsize:]\n",
    "    \n",
    "    return (trainset, trainlabels), (valset, valabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "train_size = 1 * 10 ** 5\n",
    "train_ratio = 0.7\n",
    "test_size = 1 * 10 ** 4\n",
    "\n",
    "# Load test data\n",
    "train_val_data = mixdata[\"X\"][:train_size]\n",
    "train_val_labels = mixdata[\"pwave\"][:train_size]\n",
    "\n",
    "(trainset, trainlabels), (valset, val_labels) = split_trainset(train_val_data, train_val_labels, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = list(zip(trainset, trainlabels))\n",
    "\n",
    "valset = list(zip(valset, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Add Multi-GPU Support to Model \n",
    "In order to run the model on multiple GPU's, we can use the nn.DataParallel layer. This layer requires that we move all tensors to the cuda:0 (the default gpu) before we can pass them through the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize(model):\n",
    "    device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "    model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CNN(\n",
       "    (conv1): Conv1d(1, 32, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "    (conv2): Conv1d(32, 64, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "    (conv3): Conv1d(64, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "    (batchnorm32): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batchnorm64): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batchnorm128): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batchnorm512): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1): Linear(in_features=4736, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout2d): Dropout2d(p=0.5)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = parallelize(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define Loss Function and Optimizer\n",
    "Here we define the loss function and optimizer. For the loss function (criterion), we use the binary cross entropy with logits loss (BCEWithLogitsLoss). This function applies a sigmoid as well as calculates the cross entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Validation\n",
    "\n",
    "## TODO -- Save model on validation improvement. Then load model when testing and evaluating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: info=<RunInfo: run_uuid='14280e0426984156a7696b4567494c32', experiment_id=0, name='', source_type=4, source_name='C:\\\\Users\\\\rober\\\\Miniconda3\\\\envs\\\\eew\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', entry_point_name=None, user_id='unknown', status=1, start_time=1551928330272, end_time=None, source_version=None, lifecycle_stage='active', artifact_uri='.\\\\mlruns\\\\0\\\\14280e0426984156a7696b4567494c32\\\\artifacts'>, data=None>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:.\\mlruns\")\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/   10] | train loss: 0.0624 | validation loss: 3.0796\n",
      "Epoch [    2/   10] | train loss: 0.0416 | validation loss: 3.2674\n",
      "Epoch [    3/   10] | train loss: 0.0355 | validation loss: 3.4383\n",
      "Epoch [    4/   10] | train loss: 0.0293 | validation loss: 3.5375\n",
      "Epoch [    5/   10] | train loss: 0.0235 | validation loss: 4.0531\n",
      "Epoch [    6/   10] | train loss: 0.0196 | validation loss: 4.1795\n",
      "Epoch [    7/   10] | train loss: 0.0143 | validation loss: 4.6855\n",
      "Epoch [    8/   10] | train loss: 0.0102 | validation loss: 5.1724\n",
      "Epoch [    9/   10] | train loss: 0.0082 | validation loss: 5.5341\n",
      "Epoch [   10/   10] | train loss: 0.0056 | validation loss: 6.0370\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, labels in trainloader:\n",
    "        # ============================================\n",
    "        #            TRAINING\n",
    "        # ============================================\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        # Clear gradients in optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model.forward(batch)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, labels.type(torch.cuda.LongTensor).view(labels.shape, 1))\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "\n",
    "            for batch, labels in val_loader:\n",
    "                # ============================================\n",
    "                #            VALIDATION\n",
    "                # ============================================\n",
    "                batch, labels = batch.to(device), labels.to(device)\n",
    "                # Forward pass\n",
    "                ouput = model.forward(batch)\n",
    "                # Calculate loss\n",
    "                loss = criterion(output, labels.type(torch.cuda.LongTensor).view(labels.shape, 1))\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "    # Print epoch summary\n",
    "    t_loss_avg = train_loss / len(trainloader)\n",
    "    v_loss_avg = val_loss / len(val_loader)\n",
    "    \n",
    "    mlflow.log_metric(\"train_loss\", t_loss_avg)\n",
    "    mlflow.log_metric(\"val_loss\", v_loss_avg)\n",
    "    \n",
    "    train_losses.append(t_loss_avg)\n",
    "    val_losses.append(v_loss_avg)\n",
    "    \n",
    "    print('Epoch [{:5d}/{:5d}] | train loss: {:6.4f} | validation loss: {:6.4f}'.format(\n",
    "            epoch+1, epochs, t_loss_avg, v_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c607404d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add learning curve plot\n",
    "train_loss = np.array(train_loss)\n",
    "\n",
    "plt.plot(train_losses, label=\"Training\")\n",
    "plt.plot(val_losses, label=\"Validation\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing Model Performance\n",
    "\n",
    "For testing model performance, we'll be using scikit learn's metrics library. Scikit learn provides a handful of builtin classfication metrics which we can take advantage of. In order to use them with pytorch, we'll have to move the tensors from GPU to CPU and convert them to numpy arrays. \n",
    "\n",
    "1. Classification Report  \n",
    "    a. Precision  \n",
    "    b. Recall  \n",
    "    c. F1 Score\n",
    "2. Accuracy\n",
    "3. AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       pwave       1.00      0.83      0.91      5000\n",
      "       noise       0.85      1.00      0.92      5000\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.93      0.91      0.91     10000\n",
      "weighted avg       0.93      0.91      0.91     10000\n",
      "\n",
      "Accuracy: 91.4%\n",
      "ROC Score:  0.9843968200000001\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "test_path = \"../test/scsn_p_2000_2017_6sec_0.5r_pick_test_mix.hdf5\"\n",
    "\n",
    "y_true, y_pred, y_probs = test_model(model, test_path, test_size, device=\"cuda\")\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=[\"pwave\", \"noise\"])\n",
    "report_dict = classification_report(y_true, y_pred, target_names=[\"pwave\", \"noise\"], output_dict=True)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "roc_auc_score = roc_auc_score(y_true, y_probs)\n",
    "\n",
    "print(report)\n",
    "print(\"Accuracy: {:.4}%\".format(accuracy * 100))\n",
    "print(\"ROC Score: \", roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_param(\"epochs\", epochs)\n",
    "mlflow.log_param(\"learning_rate\", lr)\n",
    "mlflow.log_param(\"device\", device)\n",
    "\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_metric(\"auc_roc_score\", roc_auc_score)\n",
    "\n",
    "for category in report_dict:\n",
    "    for metric, value in report_dict[category].items():\n",
    "        metric_name = category + \"_\" + metric\n",
    "        mlflow.log_metric(metric_name, value)\n",
    "        \n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2017JB015251\n",
    "2. http://scedc.caltech.edu/research-tools/deeplearning.html#picking_polarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
